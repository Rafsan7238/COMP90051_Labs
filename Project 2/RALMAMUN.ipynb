{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zFoS3xPTQzl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# COMP90051 Project 2\n",
    "\n",
    "**Copyright statement:** This notebook is copyright University of Melbourne. \n",
    "It is licensed for the sole purpose of your assessment in COMP90051. \n",
    "You are not permitted to share or publish derived versions of this notebook, other than with COMP90051 staff for assessment.\n",
    "\n",
    "***\n",
    "\n",
    "The code block below imports the namespaces/functions/classes you may use in the project. \n",
    "Additional imports are not permitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWLjrI_bTQzp",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Do not edit. These are the only imports permitted.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import ndarray\n",
    "from typing import List, Optional, Tuple, Callable\n",
    "import random\n",
    "import copy\n",
    "import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "RND_SEED = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtK9nsSWTQzq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The base `SVM` class below defines a common interface for a support vector machine. \n",
    "Your implementations below for each task of the project should inherit from this class. Feel free to add to this class if you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2AGnQc4TQzr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SVM(ABC):\n",
    "    \"\"\"Base class for a support vector machine (SVM)\"\"\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def fit(self, X, y) -> None:        \n",
    "        \"\"\"Fit the model with the given training data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        X : float numpy.ndarray, shape (n_samples, n_features)\n",
    "            An array of training instances. \n",
    "        y : int {-1,1} numpy.ndarray, shape (n_samples,)\n",
    "            Labels array relative to training instances.\n",
    "        -------\n",
    "        \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, test_X) -> int:\n",
    "        \"\"\"Predict label for given test samples\n",
    "\n",
    "        Parameters\n",
    "        ----------        \n",
    "        test_X : float numpy.ndarray, shape (n_samples, n_features)\n",
    "            An array of test instances. \n",
    "\n",
    "        -------\n",
    "        Return \n",
    "        y : int {-1,1} numpy.ndarray, shape (n_samples,)\n",
    "            Predict labels array for test samples.\n",
    "        \"\"\"\n",
    "        \n",
    "    def evaluate(self, test_X, test_y) -> int:\n",
    "        \"\"\"Return the mean accuracy on the given test samples and labels.\n",
    "\n",
    "        Parameters\n",
    "        ----------        \n",
    "        test_X : float numpy.ndarray, shape (n_samples, n_features)\n",
    "            An array of test instances. \n",
    "        test_y : int {-1,1} numpy.ndarray, shape (n_samples,)\n",
    "            Labels array relative to training instances.\n",
    "        -------\n",
    "        Return : float, mean accuracy\n",
    "\n",
    "        \"\"\"\n",
    "            \n",
    "        pred_y = self.predict(test_X)\n",
    "        acc = (pred_y == test_y).sum() / len(test_y)\n",
    "        return acc\n",
    "    \n",
    "    def visualize(self, X, y) -> None:\n",
    "        \"\"\"Plot data and decision surface of fitted model. \n",
    "        This function is adapted from \n",
    "        https://stackoverflow.com/questions/51297423/plot-scikit-learn-sklearn-svm-decision-boundary-surface\n",
    "\n",
    "        Parameters\n",
    "        ----------        \n",
    "        X : float numpy.ndarray, shape (n_samples, n_features)\n",
    "            An array of instances. \n",
    "        y : int {-1,1} numpy.ndarray, shape (n_samples,)\n",
    "            Labels array relative to X.\n",
    "        -------\n",
    "        \"\"\"\n",
    "        y = np.array(y).squeeze()\n",
    "        X = np.array(X)\n",
    "        \n",
    "        assert X.ndim == 2, \"The shape of X must be (n_samples, n_features)\"\n",
    "        assert X.shape[0] == y.shape[0], \"Inconsistent number of instances and labels\"\n",
    "        assert set(y) == set([1,-1]), \"Labels must be 1 or -1\"\n",
    "        \n",
    "        def make_meshgrid(x, y, h=.02):\n",
    "            x_min, x_max = x.min() - 1, x.max() + 1\n",
    "            y_min, y_max = y.min() - 1, y.max() + 1\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "            return xx, yy\n",
    "\n",
    "        def plot_contours(ax, clf, xx, yy, **params):\n",
    "            Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            out = ax.contourf(xx, yy, Z, **params)\n",
    "            return out\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        title = ('Decision surface of SVM')\n",
    "        # Set-up grid for plotting.\n",
    "        X0, X1 = X[:, 0], X[:, 1]\n",
    "        xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "        plot_contours(ax, self, xx, yy, cmap=plt.cm.Pastel1)\n",
    "        ax.scatter(X[y==-1,0], X[y==-1,1], color='b', label=\"$y = -1$\")\n",
    "        ax.scatter(X[y==1,0], X[y==1,1], color='r', label=\"$y = 1$\")\n",
    "\n",
    "        ax.set_ylabel('$x_1$')\n",
    "        ax.set_xlabel('$x_2$')\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrrak7iQTQzs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Binary classification data\n",
    "We will generate some toy binary classification data, re-using the code from workshop 4. This will be used for tasks 1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTxReDklTQzt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples = 30, n_features = 2, n_informative=2, n_redundant=0, random_state=RND_SEED)\n",
    "y = np.where(y <=0, -1, 1)\n",
    "X_b = np.column_stack((np.ones_like(y), X))\n",
    "\n",
    "plt.scatter(X[y==-1,0], X[y==-1,1], color='b', label=\"$y = -1$\")\n",
    "plt.scatter(X[y==1,0], X[y==1,1], color='r', label=\"$y = 1$\")\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSBvj08vTQzu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 1: Primal soft-margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LhmCIFtNTQzv",
    "outputId": "613ca0a6-04bf-4c7a-e9ae-e87e8632e761",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PrimalSVM(SVM):\n",
    "    \"\"\"Soft-margin SVM fit using primal objective, training \n",
    "    with stochastic gradient ascent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eta : float\n",
    "        Learning rate.\n",
    "    lambda0: float\n",
    "        Regularisation term, must be strictly positive\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eta, lambda0) -> None:\n",
    "        super().__init__()\n",
    "        ## your code here\n",
    "        ### end of your code ###\n",
    "        \n",
    "    def fit(self, X, y, iterations = 100) -> None:\n",
    "        super().fit(X=X,y=y)\n",
    "        ## your code here ###\n",
    "        ### end of your code ###\n",
    "        \n",
    "            \n",
    "    def predict(self, test_X) -> int: \n",
    "        super().predict(test_X = test_X)\n",
    "        ## your code here ###\n",
    "        ### end of your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUOyat7BTQzw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "psvm = PrimalSVM(eta = 0.1, lambda0=0.1)\n",
    "psvm.fit(X,y, iterations = 100)\n",
    "print(f\"Accuracy is {round(psvm.evaluate(X,y),4)}\")\n",
    "psvm.visualize(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ifa1T-Q4TQzx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tuning lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6c2O01kgTQzx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell for experimentation 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vECMC_JLTQzy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 2: Dual soft-margin SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNLjRbT4TQzy",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DualSVM(SVM):\n",
    "    \"\"\"Soft-margin SVM using dual formulation, training \n",
    "    with stochastic gradient ascent\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eta : float\n",
    "        Learning rate.\n",
    "    C: float\n",
    "        Regularization parameter.\n",
    "    kernel: Kernel\n",
    "        Kernel function\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eta, C, kernel = None):\n",
    "        super().__init__()\n",
    "        if kernel is None:\n",
    "            def dot_product(u,v):\n",
    "                return np.dot(u, v.T)\n",
    "            self.kernel = dot_product\n",
    "        else:\n",
    "            self.kernel = kernel\n",
    "            \n",
    "        ## your code here ###\n",
    "        ### end of your code ###\n",
    "    \n",
    "    def fit(self, X, y, iterations = 100):\n",
    "        \n",
    "        super().fit(X=X,y=y)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        ### your code here ###\n",
    "        self.alphas = ... # lagrange multipliers (sometimes denoted lambda), you should initialize with 0s\n",
    "        \n",
    "        ### end of your code ###\n",
    "        self.bias = self.get_bias()\n",
    "            \n",
    "        return \n",
    "     \n",
    "    def predict(self, test_X):\n",
    "        super().predict(test_X =test_X)\n",
    "        ### your code here ###\n",
    "        ### end of your code ###\n",
    "    \n",
    "    def primal_weights(self):\n",
    "        \"\"\"Compute weights based on alphas, assuming linear kernel\n",
    "        \"\"\"\n",
    "        ### your code here ###\n",
    "        ### end of your code ###\n",
    "        \n",
    "    def get_bias(self):\n",
    "        \"\"\"Compute bias based on learned alphas and training data set\n",
    "        \"\"\"\n",
    "        ### your code here ###\n",
    "        ### end of your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BzkZq-pTQzz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dsvm = DualSVM(eta = 0.1, C = 100)\n",
    "dsvm.fit(X,y, iterations = 100)\n",
    "print(f\"Accuracy is {round(dsvm.evaluate(X,y),4)}\")\n",
    "dsvm.visualize(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k0BwigQTQz0",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tuning C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Srmy8iqTQz0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell here for experimentation 2.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUgJXTtkTQz1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compare weights between primal and dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kqci-HzBTQz1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell here for experimentation 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldjRwqnxfuyi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Identify support vectors and points where alpha=C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RR1V8TgFfvkf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell here for experimentation 2.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMqqnJaATQz1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Task 3: Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNmMdmhfTQz1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "    \n",
    "class Kernel():\n",
    "    \"\"\"Kernel class\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel_type : str {linear, poly, rbf}\n",
    "        Type of kernel be indicated.\n",
    "    poly_degree: int\n",
    "        Polynomial degree for polynormial kernel. \n",
    "    poly_offset: float\n",
    "        Polynomial offset for polynomial kernel. \n",
    "    rbf_sigma: float\n",
    "        Kernel coefficient for rbf kernel. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_type = None, **kwargs):\n",
    "        if kernel_type == \"linear\":\n",
    "            self.kernel = self.linear_kernel\n",
    "        if kernel_type == \"poly\":\n",
    "            self.degree = kwargs.get('poly_degree')\n",
    "            self.sigma = kwargs.get('poly_offset')\n",
    "            self.kernel = self.poly_kernel\n",
    "        if kernel_type == \"rbf\":\n",
    "            self.sigma = kwargs.get('rbf_sigma')\n",
    "            self.kernel = self.rbf_kernel\n",
    "            \n",
    "    def __call__(self,u,v):\n",
    "        \"\"\"Evaluate the kernel on a pair of inputs, possibly batched.\n",
    "        Matrix input is comprised of instances as row vectors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        u: vector or matrix\n",
    "            first instance(s), shape (n,) or (m,n)\n",
    "        v: vector or matrix\n",
    "            second instance(s), shape (n,) or (z,n)\n",
    "        \n",
    "        -------\n",
    "        Return : Kernel matrix, float or shape(z,) or shape (m,z)\n",
    "\n",
    "        \"\"\"\n",
    "        return self.kernel(u, v)\n",
    "        \n",
    "    def linear_kernel(self, u, v):\n",
    "        return np.dot(u,v.T)\n",
    "\n",
    "    def poly_kernel(self, u, v):\n",
    "        ### your code here ###\n",
    "        \n",
    "        ### end of your code ###\n",
    "\n",
    "    def rbf_kernel(self, u, v):\n",
    "        ### your code here ###\n",
    "        \n",
    "        ### end of your code ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3oDvTw5TQz2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test your kernel in the DualSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9z-7gUahTQz2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell here for experimentation 3, e.g., \n",
    "\n",
    "svm = DualSVM(eta = 0.1, C = 100, kernel = Kernel('linear'))\n",
    "svm.fit(X,y, iterations = 100)\n",
    "print(f\"Accuracy is {round(svm.evaluate(X,y),4)}\")\n",
    "svm.visualize(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[In a few sentences, explain which kernel you think is best suited to this problem, and why.]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "project2-svm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}