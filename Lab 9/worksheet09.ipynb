{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsMJ2K-CsKp1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Workshop 9: Seq2Seq and Transformer\n",
    "\n",
    "In this workshop, we'll implement a transformer, from paper\"Attention is all you need\", to build a sequence to sequence model for machine translation. The workshop is based on the Pytorch [Transformer Tutorial](https://pytorch.org/tutorials/beginner/translation_transformer.html).\n",
    "\n",
    "This tutorial shows:\n",
    "    - How to implement Encoder and Decoder for Transformer.\n",
    "    - How to train a translation model from scratch using Transformer.\n",
    "    - Use torchtext library to access Multi30k dataset to train a German to English translation model.\n",
    "First, make sure to install the dependencies, and restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwVjR9cXUNi5",
    "outputId": "5e70dbfe-4085-4efe-87f7-61f669c7b626",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdata in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (0.6.1)\r\n",
      "Requirement already satisfied: urllib3>=1.25 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torchdata) (2.0.4)\r\n",
      "Requirement already satisfied: requests in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torchdata) (2.31.0)\r\n",
      "Requirement already satisfied: torch==2.0.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torchdata) (2.0.1)\r\n",
      "Requirement already satisfied: filelock in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (4.7.1)\r\n",
      "Requirement already satisfied: sympy in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (1.12)\r\n",
      "Requirement already satisfied: networkx in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from torch==2.0.1->torchdata) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests->torchdata) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests->torchdata) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests->torchdata) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchdata) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\r\n",
      "Requirement already satisfied: spacy in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (8.1.12)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (2.4.7)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (2.0.9)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (0.9.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (0.10.2)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (4.65.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (1.23.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (2.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (68.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy) (3.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.6.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\r\n",
      "Collecting en-core-web-sm==3.6.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m14.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from en-core-web-sm==3.6.0) (3.6.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (68.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.6.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('en_core_web_sm')\r\n",
      "Collecting de-core-news-sm==3.6.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m14.6/14.6 MB\u001B[0m \u001B[31m14.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from de-core-news-sm==3.6.0) (3.6.1)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.10)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.8)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.12)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.7)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.9)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.2)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.4.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.65.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.23.4)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.3.0)\r\n",
      "Requirement already satisfied: jinja2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (68.0.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.5.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.6.3 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.6.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.7.22)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.10)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.7)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\r\n",
      "\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\n",
      "You can now load the package via spacy.load('de_core_news_sm')\r\n",
      "Requirement already satisfied: portalocker>=2.0.0 in /Users/rafsanalmamun/miniforge3/lib/python3.10/site-packages (2.8.2)\r\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "!pip install -U torchdata\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "!pip install 'portalocker>=2.0.0'\n",
    "\n",
    "#restart kernel after you install those packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Evt_ihAfQap",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Data Sourcing and Processing\n",
    "\n",
    "[torchtext library](https://pytorch.org/text/stable/) has utilities for creating datasets that can be easily\n",
    "iterated through for the purposes of creating a language translation\n",
    "model. In this example, we show how to use torchtext's inbuilt datasets,\n",
    "tokenize a raw text sentence, build vocabulary, and numericalize tokens into tensor. We will use\n",
    "[Multi30k dataset from torchtext library](https://pytorch.org/text/stable/datasets.html#multi30k)\n",
    "that yields a pair of source-target raw sentences.\n",
    "\n",
    "To access torchtext datasets, please install torchdata following instructions at https://github.com/pytorch/data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2JCqU3rsfQap",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.datasets import multi30k, Multi30k\n",
    "from typing import Iterable, List\n",
    "\n",
    "\n",
    "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
    "\n",
    "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
    "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
    "\n",
    "SRC_LANGUAGE = 'de'\n",
    "TGT_LANGUAGE = 'en'\n",
    "\n",
    "# Place-holders\n",
    "token_transform = {}\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QRs05GEefQaq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "\n",
    "# helper function to yield list of tokens\n",
    "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    # Training data Iterator\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    # Create torchtext's Vocab object\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
    "                                                    min_freq=1,\n",
    "                                                    specials=special_symbols,\n",
    "                                                    special_first=True)\n",
    "\n",
    "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
    "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NCdOTHI3Usgq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ssk4sJfsKp5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Machine Translation\n",
    "\n",
    "Machine translation is a subfield of natural language processing (NLP) that involves automatically translating text or speech from one language to another using computational techniques. The goal of machine translation is to produce output that accurately conveys the meaning of the source text or speech in the target language.\n",
    "\n",
    "One of the most widely used machine translation techniques is the sequence-to-sequence (seq2seq) model. The seq2seq model consists of two main components: an encoder and a decoder. The encoder processes the input sequence (e.g., a sentence in the source language) and produces a fixed-length vector representation of the input. The decoder then takes this vector representation as input and generates the output sequence (e.g., a sentence in the target language).\n",
    "Today, we will train a translation model from scratch with Transformer.\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/The_transformer_encoders_decoders.png\" alt=\"Machine Translation\" width=\"512\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D-ffFS2sKp6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic components\n",
    "\n",
    "#### TransformerEncoder\n",
    "\n",
    "Encoder part of an architecture is responsible for processing the input and transforming it into a hidden representation. This hidden representation is then passed on to the Decoder part of the architecture. In the context of the Transformer model, the Encoder consists of a stack of identical layers, each of which has two sub-layers: a multi-head self-attention and a fully connected feedforward network. The multi-head self-attention allows the Encoder to attend to different parts of the input sequence simultaneously, while the fully connected feedforward network applies the same transformation to each position in the sequence independently. The output of each layer is then passed on to the next layer, until the final layer produces the hidden representation of the input text.\n",
    "\n",
    "<img src=\"http://jalammar.github.io/images/t/encoder_with_tensors_2.png\" alt=\"Encoder\" width=\"512\"/>\n",
    "\n",
    "\n",
    "We will first implement `TransformerEncoderLayer`, then stack multipe `TransformerEncoderLayer` to construct `TransformerEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0Uy5-gB_UjTn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Transformer encoder layer.\n",
    "        emb_dim: the number of expected features in the input .\n",
    "        nhead: the number of heads in the multiheadattention models.\n",
    "        ff_dim: the dimension of the feedforward network model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, nhead, ff_dim):\n",
    "#         factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "        \n",
    "        #Implementation of self attention model\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, nhead)\n",
    "        \n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "        self.activation = F.relu\n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask = None, src_key_padding_mask = None):\n",
    "        \"\"\"\n",
    "        Pass the input through the encoder layer.\n",
    "            src: the sequence to the encoder layer.\n",
    "        \"\"\"\n",
    "\n",
    "        x = src\n",
    "        x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask)\n",
    "        x = x + self._ff_block(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "    # self-attention block\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask):\n",
    "        x = self.self_attn(x, x, x,\n",
    "                           attn_mask=attn_mask,\n",
    "                           key_padding_mask=key_padding_mask,\n",
    "                           need_weights=False)[0]\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    # feed forward block\n",
    "    def _ff_block(self, x):\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        return self.dropout2(x)\n",
    "    \n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    TransformerEncoder is a stack of N encoder layers. \n",
    "        encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
    "        num_layers: the number of sub-encoder-layers in the encoder (required).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_layer, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([copy.deepcopy(encoder_layer) for i in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, src, mask = None, src_key_padding_mask = None):\n",
    "        \"\"\"\n",
    "        Pass the input through the encoder layers in turn.\n",
    "            src: the sequence to the encoder (required).\n",
    "            mask: the mask for the src sequence (optional).\n",
    "            src_key_padding_mask: the mask for the src keys per batch (optional).\n",
    "        \"\"\"\n",
    "\n",
    "        output = src\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPasX6CAsKp6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### TransformerDeocder\n",
    "\n",
    "The Decoder is designed to generate an output sequence using a hidden representation that is usually generated by an Encoder. The Transformer Decoder, specifically, is composed of several identical layers, each of which contains three sub-layers. Along with the multi-head self-attention mechanism and the feedforward layer, which are similar to those in the Encoder, the Decoder also includes an extra sub-layer that implements multi-head attention over the Encoder's output.\n",
    "\n",
    "Here are the steps for implementing the `TransformerDecoderLayer` and `TransformerDecoder` in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p0FyHnRKUmGr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Transformer decoder layer.\n",
    "        emb_dim: the number of expected features in the input .\n",
    "        nhead: the number of heads in the multiheadattention models.\n",
    "        ff_dim: the dimension of the feedforward network model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, nhead, ff_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Implementation of self attention model\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, nhead)\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, nhead)\n",
    "        \n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "\n",
    "        self.activation = F.relu\n",
    "\n",
    "\n",
    "    def forward( self, tgt, memory, tgt_mask = None, memory_mask = None, \n",
    "                tgt_key_padding_mask = None, memory_key_padding_mask = None):\n",
    "        \"\"\"\n",
    "        Pass the inputs through the decoder layer.\n",
    "            tgt: the sequence to the decoder layer.\n",
    "            memory: the sequence from the last layer of the encoder.\n",
    "        \"\"\"\n",
    "\n",
    "        x = tgt\n",
    "        x = x + self._sa_block(self.norm1(x), tgt_mask, tgt_key_padding_mask)\n",
    "        x = x + self._mha_block(self.norm2(x), memory, memory_mask, memory_key_padding_mask)\n",
    "        x = x + self._ff_block(self.norm3(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    # self-attention block\n",
    "    def _sa_block(self, x, attn_mask, key_padding_mask):\n",
    "        x = self.self_attn(x, x, x,\n",
    "                           attn_mask=attn_mask,\n",
    "                           key_padding_mask=key_padding_mask,\n",
    "                           need_weights=False)[0]\n",
    "        return self.dropout1(x)\n",
    "\n",
    "    # multihead attention block\n",
    "    def _mha_block(self, x, mem, attn_mask, key_padding_mask):\n",
    "        x = self.multihead_attn(x, mem, mem,\n",
    "                                attn_mask=attn_mask,\n",
    "                                key_padding_mask=key_padding_mask,\n",
    "                                need_weights=False)[0]\n",
    "        return self.dropout2(x)\n",
    "\n",
    "    # feed forward block\n",
    "    def _ff_block(self, x):\n",
    "        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        return self.dropout3(x)\n",
    "    \n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    TransformerDecoder is a stack of N decoder layers\n",
    "        decoder_layer: an instance of the TransformerDecoderLayer() class (required).\n",
    "        num_layers: the number of sub-decoder-layers in the decoder (required).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, decoder_layer, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = self.layers = nn.ModuleList([copy.deepcopy(decoder_layer) for i in range(num_layers)])\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask= None,\n",
    "                memory_mask= None, tgt_key_padding_mask = None,\n",
    "                memory_key_padding_mask = None):\n",
    "        \"\"\"\n",
    "        Pass the inputs (and mask) through the decoder layer in turn.\n",
    "            tgt: the sequence to the decoder (required).\n",
    "            memory: the sequence from the last layer of the encoder (required).\n",
    "            tgt_mask: the mask for the tgt sequence (optional).\n",
    "            memory_mask: the mask for the memory sequence (optional).\n",
    "            tgt_key_padding_mask: the mask for the tgt keys per batch (optional).\n",
    "            memory_key_padding_mask: the mask for the memory keys per batch (optional).\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, memory, tgt_mask=tgt_mask,\n",
    "                         memory_mask=memory_mask,\n",
    "                         tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                         memory_key_padding_mask=memory_key_padding_mask)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tohkuyZlsKp7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Seq2Seq Network using Transformer\n",
    "\n",
    "Transformer is a Seq2Seq model introduced in [“Attention is all you\n",
    "need”](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)\n",
    "paper for solving machine translation tasks.\n",
    "Below, we will create a Seq2Seq network that uses Transformer. \n",
    "The network consists of three parts. First part is the embedding layer. This layer converts tensor of input indices\n",
    "into corresponding tensor of input embeddings. These embedding are further augmented with positional\n",
    "encodings to provide position information of input tokens to the model. The second part is the\n",
    "actual [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html) model.\n",
    "Finally, the output of the Transformer model is passed through linear layer\n",
    "that gives unnormalized probabilities for each token in the target language.\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png\" alt=\"Encoder\" width=\"512\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MVayzEFfQar",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size,\n",
    "                 dropout,\n",
    "                 maxlen = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 emb_size,\n",
    "                 nhead,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 ff_dim,\n",
    "                 dropout=0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "\n",
    "        \n",
    "        # we used our own implementation of encoder and decoder, \n",
    "        # you can remove custom_encoder and custom_decoder keyword to use PyTorch implementation\n",
    "        \n",
    "        encoder_layer = TransformerEncoderLayer(emb_size, nhead, ff_dim)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "        decoder_layer = TransformerDecoderLayer(emb_size, nhead, ff_dim)\n",
    "        self.decoder = TransformerDecoder(decoder_layer, num_encoder_layers)\n",
    "        \n",
    "        self.transformer = nn.Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=ff_dim,\n",
    "                                       custom_encoder = self.encoder,\n",
    "                                       custom_decoder = self.decoder) \n",
    "        \n",
    "        \n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src,\n",
    "                trg,\n",
    "                src_mask,\n",
    "                tgt_mask,\n",
    "                src_padding_mask,\n",
    "                tgt_padding_mask,\n",
    "                memory_key_padding_mask):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NA1rYrvfQas",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "During training, we need a subsequent word mask that will prevent the model from looking into\n",
    "the future words when making predictions. We will also need masks to hide\n",
    "source and target padding tokens. Below, let's define a function that will take care of both.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnYjF48YfQas",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ip9vVy1VfQat",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now define the parameters of our model and instantiate the same. Below, we also\n",
    "define our loss function which is the cross-entropy loss and the optimizer used for training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OptF8ukfQat",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX) # we need to ignore padding index\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oawdWoqfQat",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Collation\n",
    "\n",
    "As seen in the ``Data Sourcing and Processing`` section, our data iterator yields a pair of raw strings.\n",
    "We need to convert these string pairs into the batched tensors that can be processed by our ``Seq2Seq`` network\n",
    "defined previously. Below we define our collate function that converts a batch of raw strings into batch tensors that\n",
    "can be fed directly into our model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyEHQAh-fQat",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# helper function to club together sequential operations\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# function to add BOS/EOS and create tensor for input sequence indices\n",
    "def tensor_transform(token_ids: List[int]):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
    "text_transform = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
    "                                               vocab_transform[ln], #Numericalization\n",
    "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
    "\n",
    "\n",
    "# function to collate data samples into batch tensors\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya7hLXY5fQau",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's define training and evaluation loop that will be called for each\n",
    "epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NIEBm7abfQau",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in train_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(train_dataloader))\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
    "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "    for src, tgt in val_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rL5vkVwWfQau",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we have all the ingredients to train our model. Let's do it!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C9hcMYTEfQav",
    "outputId": "c163f353-47b6-45f3-f89f-195548a134c2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "\n",
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(\n",
    "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qrDA3-IZFkZ",
    "outputId": "546c6ed8-f634-478e-dfad-75ccdab36176",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}